{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jAFDxR-Xx1J",
        "outputId": "61fb8cf3-57e5-4d73-b34f-35bbe13b3a27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt_tab')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# stemming\n",
        "\n",
        "stemmer = PorterStemmer()"
      ],
      "metadata": {
        "id": "CX2_OKACdBGU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"The runner were running very fast in the race, and I ran behind the runners\""
      ],
      "metadata": {
        "id": "ADw6x_RvdIXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = word_tokenize(sentence)\n",
        "tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycSE4MfFdUUQ",
        "outputId": "688ad412-80ed-43f7-de71-e5888e8ef096"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'runner',\n",
              " 'were',\n",
              " 'running',\n",
              " 'very',\n",
              " 'fast',\n",
              " 'in',\n",
              " 'the',\n",
              " 'race',\n",
              " ',',\n",
              " 'and',\n",
              " 'I',\n",
              " 'ran',\n",
              " 'behind',\n",
              " 'the',\n",
              " 'runners']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stemmer.stem('running')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "mQnVXbGldik6",
        "outputId": "7811949c-060b-48a5-f48f-6ec09140cb3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'run'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words = []\n",
        "for i in tokens:\n",
        "\n",
        "  stem_words.append(stemmer.stem(i))\n"
      ],
      "metadata": {
        "id": "pP7mvVLWdsRd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mMywoCTiecJa",
        "outputId": "8be7dc86-5048-4442-caec-60be4eb1c0ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'runner', 'were', 'running', 'very', 'fast', 'in', 'the', 'race', ',', 'and', 'I', 'ran', 'behind', 'the', 'runners']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stem_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GOOs7JbeQmn",
        "outputId": "9955bf12-3ea6-4fdf-ec22-5db891f1388c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the',\n",
              " 'runner',\n",
              " 'were',\n",
              " 'run',\n",
              " 'veri',\n",
              " 'fast',\n",
              " 'in',\n",
              " 'the',\n",
              " 'race',\n",
              " ',',\n",
              " 'and',\n",
              " 'i',\n",
              " 'ran',\n",
              " 'behind',\n",
              " 'the',\n",
              " 'runner']"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmetization\n",
        "\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrM-ITRveTDV",
        "outputId": "7c9162ec-81dd-4f68-ab34-653b8b4fd32e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmetizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "mS9L-J6Ae9Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemetized_words = [lemmetizer.lemmatize(word,pos = 'v') for word in tokens]\n",
        "lemetized_words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8C0INaofDyT",
        "outputId": "57d78f3c-f04b-4b26-9fc1-a7c6a1207825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The',\n",
              " 'runner',\n",
              " 'be',\n",
              " 'run',\n",
              " 'very',\n",
              " 'fast',\n",
              " 'in',\n",
              " 'the',\n",
              " 'race',\n",
              " ',',\n",
              " 'and',\n",
              " 'I',\n",
              " 'run',\n",
              " 'behind',\n",
              " 'the',\n",
              " 'runners']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXe4eUZRfgKS",
        "outputId": "705789c4-38a2-45b2-8d7a-a2e63798911a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'runner', 'were', 'running', 'very', 'fast', 'in', 'the', 'race', ',', 'and', 'I', 'ran', 'behind', 'the', 'runners']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(lemetized_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFlqfcABfi7U",
        "outputId": "59860f70-0c25-46ed-84e7-8dfaa21dafe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'runner', 'be', 'run', 'very', 'fast', 'in', 'the', 'race', ',', 'and', 'I', 'run', 'behind', 'the', 'runners']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using Spacy library\n",
        "\n",
        "import spacy\n",
        "\n",
        "# Load the English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "text = \"The striped bats are hanging on their feet and ate the best fruits\"\n",
        "\n",
        "# Process text\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(f\"Token: {token.text}  -->  Lemma: {token.lemma_}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wajfWtrUfk7z",
        "outputId": "7d6f848e-bbe8-4141-efbd-bb2ae6a67f74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: The  -->  Lemma: the\n",
            "Token: striped  -->  Lemma: striped\n",
            "Token: bats  -->  Lemma: bat\n",
            "Token: are  -->  Lemma: be\n",
            "Token: hanging  -->  Lemma: hang\n",
            "Token: on  -->  Lemma: on\n",
            "Token: their  -->  Lemma: their\n",
            "Token: feet  -->  Lemma: foot\n",
            "Token: and  -->  Lemma: and\n",
            "Token: ate  -->  Lemma: eat\n",
            "Token: the  -->  Lemma: the\n",
            "Token: best  -->  Lemma: good\n",
            "Token: fruits  -->  Lemma: fruit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5j4cVnjgc1f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}